{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget --no-check-certificate \\\n",
    "#   https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
    "#   -O cats_and_dogs_filtered.zip\n",
    "# ! unzip cats_and_dogs_filtered.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System setting and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using plaidml.keras.backend backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "\n",
    "os.environ[\"RUNFILES_DIR\"] = \"/Users/bunnykitty/opt/anaconda3/envs/tf/share/plaidml\"\n",
    "# plaidml might exist in different location. Look for \"/usr/local/share/plaidml\" and replace in above path\n",
    "\n",
    "os.environ[\"PLAIDML_NATIVE_PATH\"] = \"/Users/bunnykitty/opt/anaconda3/envs/tf/lib/libplaidml.dylib\"\n",
    "# libplaidml.dylib might exist in different location. Look for \"/usr/local/lib/libplaidml.dylib\" and replace in above path\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, AveragePooling2D,GlobalAveragePooling2D, Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "trdata = ImageDataGenerator()\n",
    "traindata = trdata.flow_from_directory(directory=\"cats_and_dogs_filtered/train\",target_size=(224,224))\n",
    "tsdata = ImageDataGenerator()\n",
    "testdata = tsdata.flow_from_directory(directory=\"cats_and_dogs_filtered/validation\", target_size=(224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup ResNet50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"metal_amd_radeon_pro_5500m.0\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras_applications import resnet\n",
    "\n",
    "# from keras.layers import Input\n",
    "# new_input = Input(shape=(224, 224, 3))\n",
    "# model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3), classes=2)\n",
    "resnet_model = resnet.ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3), \n",
    "#                         classes=2,\n",
    "                        backend=keras.backend,\n",
    "                        layers=keras.layers,\n",
    "                        models=keras.models,\n",
    "                        utils=keras.utils)\n",
    "\n",
    "# for layer in resnet_model.layers:\n",
    "#     layer.trainable = False\n",
    "    \n",
    "resnet_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.applications.resnet152 import ResNet152\n",
    "\n",
    "# model = ResNet152(weights='imagenet', include_top=False, input_shape=(224, 224, 3), classes=2)\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 24,639,874\n",
      "Trainable params: 24,585,730\n",
      "Non-trainable params: 54,144\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "model = Sequential()\n",
    "# model.add(UpSampling2D())\n",
    "# model.add(UpSampling2D())\n",
    "# model.add(UpSampling2D())\n",
    "model.add(resnet_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "# model.add(MaxPool2D())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# x = resnet_model.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# x = Dropout(0.7)(x)\n",
    "# predictions = Dense(2, activation= 'softmax')(x)\n",
    "# model = Model(inputs = resnet_model.input, outputs = predictions)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = resnet_model.output\n",
    "# output = keras.layers.Flatten()(output)\n",
    "# output = Dense(2, activation=\"softmax\")(output)\n",
    "# model = Model(resnet_model.input, output=output)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='resnet50.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModelCheckpoint and EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "# checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "# early = EarlyStopping(monitor='val_acc', min_delta=0, patience=40, verbose=1, mode='auto')\n",
    "# model_final.fit_generator(generator= traindata, steps_per_epoch= 2, epochs= 100, validation_data= testdata, validation_steps=1, callbacks=[checkpoint,early])\n",
    "# model_final.save_weights(\"vgg16_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "opt = Adam(lr=0.001)\n",
    "# opt=optimizers.SGD(lr=0.0001, momentum=0.9)\n",
    "# opt=optimizers.RMSprop(lr=2e-5)\n",
    "# for layers in (vggmodel.layers)[:19]:\n",
    "#     print(layers)\n",
    "#     layers.trainable = False\n",
    "    \n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = opt, metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 107s 5s/step - loss: nan - acc: 0.5205 - val_loss: nan - val_acc: 0.4844\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.48438, saving model to saved_model/resnet50_imagenet_2.h5\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 128s 6s/step - loss: nan - acc: 0.4969 - val_loss: nan - val_acc: 0.4875\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.48438 to 0.48750, saving model to saved_model/resnet50_imagenet_2.h5\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 133s 7s/step - loss: nan - acc: 0.4766 - val_loss: nan - val_acc: 0.5219\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.48750 to 0.52187, saving model to saved_model/resnet50_imagenet_2.h5\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 149s 7s/step - loss: nan - acc: 0.5174 - val_loss: nan - val_acc: 0.5101\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.52187\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 142s 7s/step - loss: nan - acc: 0.4828 - val_loss: nan - val_acc: 0.5188\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.52187\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 136s 7s/step - loss: nan - acc: 0.5172 - val_loss: nan - val_acc: 0.4969\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.52187\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 145s 7s/step - loss: nan - acc: 0.4768 - val_loss: nan - val_acc: 0.4865\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.52187\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 148s 7s/step - loss: nan - acc: 0.5094 - val_loss: nan - val_acc: 0.4875\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.52187\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 145s 7s/step - loss: nan - acc: 0.5016 - val_loss: nan - val_acc: 0.5062\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.52187\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 150s 7s/step - loss: nan - acc: 0.5141 - val_loss: nan - val_acc: 0.4966\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.52187\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 155s 8s/step - loss: nan - acc: 0.4781 - val_loss: nan - val_acc: 0.4813\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.52187\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 146s 7s/step - loss: nan - acc: 0.4891 - val_loss: nan - val_acc: 0.4938\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.52187\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 165s 8s/step - loss: nan - acc: 0.4876 - val_loss: nan - val_acc: 0.5270\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.52187 to 0.52703, saving model to saved_model/resnet50_imagenet_2.h5\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 157s 8s/step - loss: nan - acc: 0.5156 - val_loss: nan - val_acc: 0.5031\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.52703\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 170s 9s/step - loss: nan - acc: 0.4704 - val_loss: nan - val_acc: 0.4594\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.52703\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 168s 8s/step - loss: nan - acc: 0.5330 - val_loss: nan - val_acc: 0.5439\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.52703 to 0.54392, saving model to saved_model/resnet50_imagenet_2.h5\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 163s 8s/step - loss: nan - acc: 0.4922 - val_loss: nan - val_acc: 0.5156\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.54392\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 161s 8s/step - loss: nan - acc: 0.4844 - val_loss: nan - val_acc: 0.4938\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.54392\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 158s 8s/step - loss: nan - acc: 0.5188 - val_loss: nan - val_acc: 0.4906\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.54392\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 165s 8s/step - loss: nan - acc: 0.4797 - val_loss: nan - val_acc: 0.5236\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.54392\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 173s 9s/step - loss: nan - acc: 0.5018 - val_loss: nan - val_acc: 0.4688\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.54392\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 160s 8s/step - loss: nan - acc: 0.5188 - val_loss: nan - val_acc: 0.5094\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.54392\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 140s 7s/step - loss: nan - acc: 0.4922 - val_loss: nan - val_acc: 0.4899\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.54392\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 83s 4s/step - loss: nan - acc: 0.4986 - val_loss: nan - val_acc: 0.4875\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.54392\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 66s 3s/step - loss: nan - acc: 0.4984 - val_loss: nan - val_acc: 0.5469\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.54392 to 0.54688, saving model to saved_model/resnet50_imagenet_2.h5\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 65s 3s/step - loss: nan - acc: 0.5109 - val_loss: nan - val_acc: 0.4392\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.54688\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 66s 3s/step - loss: nan - acc: 0.4953 - val_loss: nan - val_acc: 0.4625\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.54688\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 67s 3s/step - loss: nan - acc: 0.5016 - val_loss: nan - val_acc: 0.5625\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.54688 to 0.56250, saving model to saved_model/resnet50_imagenet_2.h5\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 77s 4s/step - loss: nan - acc: 0.5063 - val_loss: nan - val_acc: 0.5169\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.56250\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 70s 4s/step - loss: nan - acc: 0.4688 - val_loss: nan - val_acc: 0.5219\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.56250\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 73s 4s/step - loss: nan - acc: 0.5266 - val_loss: nan - val_acc: 0.5000\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.56250\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 66s 3s/step - loss: nan - acc: 0.4953 - val_loss: nan - val_acc: 0.4662\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.56250\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 67s 3s/step - loss: nan - acc: 0.5219 - val_loss: nan - val_acc: 0.5094\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.56250\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 68s 3s/step - loss: nan - acc: 0.4859 - val_loss: nan - val_acc: 0.5094\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.56250\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 76s 4s/step - loss: nan - acc: 0.4734 - val_loss: nan - val_acc: 0.4938\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.56250\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 67s 3s/step - loss: nan - acc: 0.5141 - val_loss: nan - val_acc: 0.4595\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.56250\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 68s 3s/step - loss: nan - acc: 0.5094 - val_loss: nan - val_acc: 0.4531\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.56250\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 84s 4s/step - loss: nan - acc: 0.5027 - val_loss: nan - val_acc: 0.5406\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.56250\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 67s 3s/step - loss: nan - acc: 0.5188 - val_loss: nan - val_acc: 0.4764\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.56250\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 67s 3s/step - loss: nan - acc: 0.4781 - val_loss: nan - val_acc: 0.5156\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.56250\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 67s 3s/step - loss: nan - acc: 0.4984 - val_loss: nan - val_acc: 0.5344\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.56250\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 68s 3s/step - loss: nan - acc: 0.4984 - val_loss: nan - val_acc: 0.5270\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.56250\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 67s 3s/step - loss: nan - acc: 0.4906 - val_loss: nan - val_acc: 0.4625\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.56250\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 77s 4s/step - loss: nan - acc: 0.5145 - val_loss: nan - val_acc: 0.5125\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.56250\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 67s 3s/step - loss: nan - acc: 0.4625 - val_loss: nan - val_acc: 0.5101\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.56250\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 77s 4s/step - loss: nan - acc: 0.4892 - val_loss: nan - val_acc: 0.4906\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.56250\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 67s 3s/step - loss: nan - acc: 0.5297 - val_loss: nan - val_acc: 0.5062\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.56250\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 76s 4s/step - loss: nan - acc: 0.5139 - val_loss: nan - val_acc: 0.4966\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.56250\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 67s 3s/step - loss: nan - acc: 0.4719 - val_loss: nan - val_acc: 0.5062\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.56250\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 67s 3s/step - loss: nan - acc: 0.4984 - val_loss: nan - val_acc: 0.4875\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.56250\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 67s 3s/step - loss: nan - acc: 0.5266 - val_loss: nan - val_acc: 0.4969\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.56250\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 77s 4s/step - loss: nan - acc: 0.5017 - val_loss: nan - val_acc: 0.5203\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.56250\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 67s 3s/step - loss: nan - acc: 0.4859 - val_loss: nan - val_acc: 0.4344\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.56250\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 68s 3s/step - loss: nan - acc: 0.5250 - val_loss: nan - val_acc: 0.5750\n",
      "\n",
      "Epoch 00054: val_acc improved from 0.56250 to 0.57500, saving model to saved_model/resnet50_imagenet_2.h5\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 66s 3s/step - loss: nan - acc: 0.4828 - val_loss: nan - val_acc: 0.5000\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.57500\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 77s 4s/step - loss: nan - acc: 0.4923 - val_loss: nan - val_acc: 0.5031\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.57500\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 68s 3s/step - loss: nan - acc: 0.4922 - val_loss: nan - val_acc: 0.4813\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.57500\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 67s 3s/step - loss: nan - acc: 0.4672 - val_loss: nan - val_acc: 0.4865\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.57500\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 77s 4s/step - loss: nan - acc: 0.5359 - val_loss: nan - val_acc: 0.5094\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.57500\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 67s 3s/step - loss: nan - acc: 0.5281 - val_loss: nan - val_acc: 0.5062\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.57500\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 78s 4s/step - loss: nan - acc: 0.4659 - val_loss: nan - val_acc: 0.4831\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.57500\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 69s 3s/step - loss: nan - acc: 0.5078 - val_loss: nan - val_acc: 0.5250\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.57500\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 68s 3s/step - loss: nan - acc: 0.5031 - val_loss: nan - val_acc: 0.4719\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.57500\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 68s 3s/step - loss: nan - acc: 0.5000 - val_loss: nan - val_acc: 0.5135\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.57500\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 67s 3s/step - loss: nan - acc: 0.5219 - val_loss: nan - val_acc: 0.4969\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.57500\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 72s 4s/step - loss: nan - acc: 0.4735 - val_loss: nan - val_acc: 0.5344\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.57500\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 84s 4s/step - loss: nan - acc: 0.5017 - val_loss: nan - val_acc: 0.4844\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.57500\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 66s 3s/step - loss: nan - acc: 0.4969 - val_loss: nan - val_acc: 0.4257\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.57500\n",
      "Epoch 69/100\n",
      "19/20 [===========================>..] - ETA: 3s - loss: nan - acc: 0.5066"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f0fa7fb276eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m                            \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                            \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                            callbacks=[checkpoint,early])\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved_model/resnet50_imagenet_weights_2.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/plaidml/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ctx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/plaidml/__init__.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1475\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mInvocation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/plaidml/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ctx, invoker)\u001b[0m\n\u001b[1;32m   1482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvoker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_parameter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaidml_schedule_invocation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvoker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_free\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaidml_free_invocation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/plaidml/__init__.py\u001b[0m in \u001b[0;36m_check_err\u001b[0;34m(self, result, func, args)\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaidml_compute_grad_wrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_err\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    771\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "# filepath=\"vgg16_{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "model_filepath=\"saved_model/resnet50_imagenet_2.h5\"\n",
    "checkpoint = ModelCheckpoint(model_filepath, \n",
    "                             monitor='val_acc', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             save_weights_only=False, \n",
    "                             mode='auto', \n",
    "                             period=1)\n",
    "early = EarlyStopping(monitor='val_acc', \n",
    "                      min_delta=0, \n",
    "                      patience=40, \n",
    "                      verbose=1, \n",
    "                      mode='auto')\n",
    "hist = model.fit_generator(steps_per_epoch=20,\n",
    "                           generator=traindata, \n",
    "                           validation_data= testdata, \n",
    "                           validation_steps=10,\n",
    "                           epochs=100,\n",
    "                           callbacks=[checkpoint,early])\n",
    "model.save_weights(\"saved_model/resnet50_imagenet_weights_2.h5\")\n",
    "model.save(model_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history[\"acc\"])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "testimgpath=\"cats_and_dogs_filtered/validation/cats/cat.2001.jpg\"\n",
    "testimgpath=\"testimg/image2.jpeg\"\n",
    "img = image.load_img(testimgpath,target_size=(224,224))\n",
    "img = np.asarray(img)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "filepath=\"saved_model/vgg16.hdf5\"\n",
    "from keras.models import load_model\n",
    "saved_model = load_model(filepath)\n",
    "output = saved_model.predict(img)\n",
    "\n",
    "if output[0][0] > output[0][1]:\n",
    "    print(\"cat\")\n",
    "else:\n",
    "    print('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
